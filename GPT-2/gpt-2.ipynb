{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8298429,"sourceType":"datasetVersion","datasetId":4929720}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T18:59:51.588024Z","iopub.execute_input":"2024-05-03T18:59:51.588454Z","iopub.status.idle":"2024-05-03T18:59:51.600944Z","shell.execute_reply.started":"2024-05-03T18:59:51.588423Z","shell.execute_reply":"2024-05-03T18:59:51.599918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:03:40.102001Z","iopub.execute_input":"2024-05-18T18:03:40.102710Z","iopub.status.idle":"2024-05-18T18:03:53.607874Z","shell.execute_reply.started":"2024-05-18T18:03:40.102681Z","shell.execute_reply":"2024-05-18T18:03:53.606838Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.9.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:03:57.915641Z","iopub.execute_input":"2024-05-18T18:03:57.916010Z","iopub.status.idle":"2024-05-18T18:04:12.801424Z","shell.execute_reply.started":"2024-05-18T18:03:57.915975Z","shell.execute_reply":"2024-05-18T18:04:12.800397Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dropout\nfrom keras.layers import Layer\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.layers import Embedding, LSTM, Bidirectional, Dropout, Dense, Input, concatenate\nfrom transformers import TFGPT2Model, GPT2Tokenizer\nfrom keras.layers import GlobalAveragePooling1D\nfrom keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:04:18.112715Z","iopub.execute_input":"2024-05-18T18:04:18.113099Z","iopub.status.idle":"2024-05-18T18:04:23.196531Z","shell.execute_reply.started":"2024-05-18T18:04:18.113063Z","shell.execute_reply":"2024-05-18T18:04:23.195456Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Data Loading and Preprocessing:\n- Reads training and validation data from preprocessed files.\n- Splits data into input sequences and labels.\n- Performs tokenization and padding.\n","metadata":{}},{"cell_type":"code","source":"X_train, y_train = [], []\nX_val, y_val = [], []\ndef read_data(file_path):\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            lines = file.readlines()\n            for line in lines:\n                # Split the line into word and label using tab delimiter\n                parts = line.strip().split('\\t')\n                if len(parts) == 2:  # Ensure both word and label are present\n                    word, label = parts\n                    if file_path.endswith('preprocessed_data.txt'):  # Assuming training data file ends with 'train.txt'\n                        X_train.append(word)\n                        y_train.append(label)\n                    elif file_path.endswith('preprocessed_val_data.txt'):  # Assuming validation data file ends with 'val.txt'\n                        X_val.append(word)\n                        y_val.append(label)\n    except Exception as e:\n        print(f\"Error reading file {file_path}: {e}\")\n\n# Load training data\nread_data('/kaggle/input/corpus/preprocessed_data.txt')\n\n# Load validation data\nread_data('/kaggle/input/corpus/preprocessed_val_data.txt') \n\nprint(len(X_train))\nprint(len(y_train))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:06:27.953685Z","iopub.execute_input":"2024-05-18T18:06:27.954672Z","iopub.status.idle":"2024-05-18T18:06:28.064966Z","shell.execute_reply.started":"2024-05-18T18:06:27.954638Z","shell.execute_reply":"2024-05-18T18:06:28.064046Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"50054\n50054\n","output_type":"stream"}]},{"cell_type":"code","source":"# Character-level embedding parameters\nchar_vocab_size = 256  # Assuming ASCII characters\nchar_embedding_dim = 50\n\n# Tokenization\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train + X_val)  # Fit tokenizer on both training and validation data\nX_train_indices = tokenizer.texts_to_sequences(X_train)\nX_val_indices = tokenizer.texts_to_sequences(X_val)\n\n# Padding sequences\nmax_sequence_length = max(\n    max(len(seq) for seq in X_train_indices if seq),  # Ensure seq is not empty\n    max(len(seq) for seq in X_val_indices if seq)      # Ensure seq is not empty\n) if X_train_indices and X_val_indices else 0  # Check if any sequences exist\nX_train_padded = pad_sequences(X_train_indices, maxlen=max_sequence_length)\nX_val_padded = pad_sequences(X_val_indices, maxlen=max_sequence_length)\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(y_train + y_val)  # Fit label encoder on both training and validation labels\ny_train_indices = label_encoder.transform(y_train)\ny_val_indices = label_encoder.transform(y_val)\n\n# Model parameters\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 100\nhidden_units = 64\nnum_classes = len(np.unique(y_train + y_val))\ninitial_lr = 0.001","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:09:46.708385Z","iopub.execute_input":"2024-05-18T18:09:46.709198Z","iopub.status.idle":"2024-05-18T18:09:48.239532Z","shell.execute_reply.started":"2024-05-18T18:09:46.709155Z","shell.execute_reply":"2024-05-18T18:09:48.238691Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### Character-Level and Word-Level Embeddings:\n- Defines parameters for character and word embeddings.\n- Learns word embeddings using Keras Tokenizer.\n- Concatenates character and word embeddings.\n","metadata":{}},{"cell_type":"code","source":"# Character input\nchar_input = Input(shape=(max_sequence_length,), dtype='int32')\nchar_embedding = Embedding(input_dim=char_vocab_size, output_dim=char_embedding_dim, input_length=max_sequence_length)(char_input)\n\n# Word input\nword_input = Input(shape=(max_sequence_length,), dtype='int32')\nword_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(word_input)\n\n# Concatenate character and word embeddings\nconcatenated_embeddings = concatenate([char_embedding, word_embedding])\n\n# Load pre-trained GPT-2 model and tokenizer\ngpt_model = TFGPT2Model.from_pretrained(\"gpt2\")\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:07:47.955495Z","iopub.execute_input":"2024-05-18T18:07:47.956462Z","iopub.status.idle":"2024-05-18T18:07:53.932200Z","shell.execute_reply.started":"2024-05-18T18:07:47.956420Z","shell.execute_reply":"2024-05-18T18:07:53.931234Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  returned by default.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1370e95fa3b9449aaa14c757ee31e860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f42a83f34e482e81e83a98e765f2f1"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFGPT2Model.\n\nAll the weights of TFGPT2Model were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de2ed7fdfd7143e5b8417d5c7692f334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2995b9ac0ab84724863671d8fe1b13db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b30f7bf2b749b7b38607b878deb299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8539d5edb4c84879985ca22e25de16f9"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### GPT-2 Model Integration:\n- Loads pre-trained GPT-2 model and tokenizer.\n- Defines a custom layer for GPT-2 integration.\n- Incorporates GPT-2 output into the model architecture.\n","metadata":{}},{"cell_type":"code","source":"class GPT2Layer(Layer):\n    def __init__(self, gpt_model, **kwargs):\n        super(GPT2Layer, self).__init__(**kwargs)\n        self.gpt_model = gpt_model\n\n    def call(self, inputs, **kwargs):\n        return self.gpt_model(inputs)[0]  # Return the output of the GPT-2 model\n\ninput_layer = Input(shape=(max_sequence_length,), dtype='int32')\ngpt_output = GPT2Layer(gpt_model)(input_layer)  # Use the custom GPT-2 layer\npooled_output = GlobalAveragePooling1D()(gpt_output)  # Reduce sequence dimension\noutput = Dense(num_classes, activation='softmax')(pooled_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:07:57.429109Z","iopub.execute_input":"2024-05-18T18:07:57.429524Z","iopub.status.idle":"2024-05-18T18:08:16.187609Z","shell.execute_reply.started":"2024-05-18T18:07:57.429494Z","shell.execute_reply":"2024-05-18T18:08:16.186723Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Model Compilation and Training:\n- Defines model architecture, compiles, and trains it.\n- Implements learning rate scheduling and early stopping.\n","metadata":{}},{"cell_type":"code","source":"# Define learning rate schedule using ReduceLROnPlateau\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n\n# Add Early Stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n\n# Define model\nmodel = Model(inputs=input_layer, outputs=output)\n\nmodel.compile(optimizer=Adam(learning_rate=initial_lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train_padded, y_train_indices, validation_data=(X_val_padded, y_val_indices), epochs=10, batch_size=32, callbacks=[lr_scheduler, early_stopping])\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_val_padded, y_val_indices)\nprint(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:13:37.377304Z","iopub.execute_input":"2024-05-18T18:13:37.378230Z","iopub.status.idle":"2024-05-18T18:19:25.838576Z","shell.execute_reply.started":"2024-05-18T18:13:37.378194Z","shell.execute_reply":"2024-05-18T18:19:25.837532Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m   5/1565\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 10.6979  ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716056034.138300     121 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716056034.174775     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6901 - loss: 2.0092","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716056063.047253     123 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1716056068.438057     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 28ms/step - accuracy: 0.6901 - loss: 2.0090 - val_accuracy: 0.7230 - val_loss: 1.6386 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m   5/1565\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.7468 - loss: 1.5728","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716056078.355255     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7332 - loss: 1.5838 - val_accuracy: 0.7230 - val_loss: 1.5962 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7380 - loss: 1.5409 - val_accuracy: 0.7231 - val_loss: 1.6147 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7351 - loss: 1.5386 - val_accuracy: 0.7230 - val_loss: 1.5944 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7362 - loss: 1.5264 - val_accuracy: 0.7230 - val_loss: 1.6342 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7389 - loss: 1.5043 - val_accuracy: 0.7232 - val_loss: 1.5731 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7342 - loss: 1.5104 - val_accuracy: 0.7230 - val_loss: 1.5557 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7356 - loss: 1.5041 - val_accuracy: 0.7230 - val_loss: 1.5502 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7343 - loss: 1.4971 - val_accuracy: 0.7232 - val_loss: 1.5422 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7327 - loss: 1.5004 - val_accuracy: 0.7231 - val_loss: 1.5237 - learning_rate: 0.0010\nRestoring model weights from the end of the best epoch: 10.\n\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7755 - loss: 1.2942\nValidation Loss: 1.5237258672714233, Validation Accuracy: 0.7231065034866333\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Evaluation:\n- Evaluates trained model on validation data.\n- Calculates and prints loss and accuracy.","metadata":{}},{"cell_type":"code","source":"# Predict probabilities for each class\ny_pred_probs = model.predict(X_val_padded)\n\n# Convert probabilities to class labels\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# Get the unique classes in the validation data\nunique_labels = np.unique(y_val_indices)\n\n# Calculate all metrics\nreport = classification_report(y_val_indices, y_pred, labels=unique_labels, target_names=label_encoder.classes_[unique_labels], output_dict=True)\n\n# Access individual metrics\naccuracy = report['accuracy']\nprecision = report['weighted avg']['precision']\nrecall = report['weighted avg']['recall']\nf1_score = report['weighted avg']['f1-score']\n\nprint(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:24:31.600532Z","iopub.execute_input":"2024-05-18T18:24:31.601289Z","iopub.status.idle":"2024-05-18T18:24:38.054053Z","shell.execute_reply.started":"2024-05-18T18:24:31.601256Z","shell.execute_reply":"2024-05-18T18:24:38.053063Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step\nAccuracy: 0.7231064763995609, Precision: 0.525359620466021, Recall: 0.7231064763995609, F1 Score: 0.6069982139565608\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]}]}